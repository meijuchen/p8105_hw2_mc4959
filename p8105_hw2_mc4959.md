p8105\_hw2\_mc4959
================
Meiju Chen
9/30/2020

    ## ── Attaching packages ────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

## Problem 1

Read and clean the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean precipitation data for 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Combine annual precipitation and convert month to a character variable.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters inner harbor, the
trashwheel collects that trash, and stores it in the dumpster. The
dataset contains information on year, month, and trash collected,
include some specific kinds of trash. There are a total of 344 rows in
our final dataset. Additional data sheets include month precipitation
data. More info:

  - The total precipitation in 2018 was 70.33 inches.
  - The median number of sports balls found in a dumpster in 2017 was 8

## Problem 2

1)  Read and clean the NYC Transit Dataset. Retain important variables.
    Convert the entry variable to a logical variable.

<!-- end list -->

``` r
nyc_subway_df = 
  read_csv(
    "./data/nyc_transit_subway_data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, YES = "TRUE", NO = "FALSE")) %>% 
  mutate(entry = as.logical(entry))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The dataset contains information of entrances and exits for each NYC
subway station. I kept some important variables, such as: line, station,
name, station latitude / longitude, routes served, entry, vending,
entrance type, and ADA compliance.

Then I cleaned the dataset, and converting the entry variable to a
logical vector(True/False). The dataset has 1868 rows by 19 columns.
However, the dataset is still untidy. It contains lots of NA values and
the information of routes are spread across the columns.

  - There are 465 distinct stations.
  - 84 stations are ADA compliant.
  - The proportion of station entrances/exits without vending allow
    entrance is 0.3770492.

<!-- end list -->

2)  Create a new dataset that tidies up the previous one, and reformat
    the data so that the route number and route name are distinct
    variables.

<!-- end list -->

``` r
tidy_subway_df =
  nyc_subway_df %>%
  mutate_at(vars(route1:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number"
  ) %>% 
  drop_na(route_number)
```

There are 60 stations that serve the A train. Of these stations, only 17
are ADA compliant.

## Problem 3

1)  Read and clean pols-month dataset.

<!-- end list -->

``` r
pols_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>%
  separate(
    mon, into = c("year", "month", "day")) %>%
   mutate(
     year = as.integer(year),
     month = as.integer(month),
     day = as.integer(day))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_month_df = 
  tibble(
    month = 1:12,
    month_name = month.name)

pols_df = 
  left_join(pols_df, pols_month_df, by = "month") %>% 
  mutate(
    month = month_name) %>% 
  select(year:rep_dem)

pols_df = 
  mutate(
    pols_df, president = 
      case_when(
        prez_dem == 1 ~ "dem",
        prez_gop == 1 ~ "gop")) %>% 
  select(-day, -prez_dem, -prez_gop)
```

2)  Read and clean snp dataset.

<!-- end list -->

``` r
snp_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  separate(
    date, into = c("month", "day", "year")) %>%
   mutate(
     month = as.integer(month),
     day = as.integer(day),
     year = as.integer(year)) %>% 
  arrange(year, month) %>% 
  relocate(year, month) %>% 
  left_join(pols_month_df, by = "month") %>% 
  mutate(month = month_name) %>% 
  select(year:close, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

3)  Tidy up the unemployment dataset.

<!-- end list -->

``` r
unemployment_df = 
  read_csv(
    "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>%
  select(
    year, January = jan, February = feb, March = mar, 
    April = apr, May = may, June = jun, July = jul, 
    August = aug, September = sep, October = oct, 
    November = nov, December = dec) %>% 
  pivot_longer(
    January:December,
    names_to = "month",
    values_to = "unemploy_percent") %>% 
  mutate(month = as.character(month),
         year = as.integer(year))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

4)  Join all datasets.

<!-- end list -->

``` r
final_df = 
  left_join(pols_df, snp_df, by = c("year", "month")) %>% 
  left_join(unemployment_df, by = c("year", "month"))
```

3 datasets are combined in the final dataset(final\_df): pols\_df,
snp\_df, and unemployment\_df.

  - The cleaned pols\_df has 822 rows and 9 columns.
  - The cleaned snp\_df has 787 rows and 3 columns.
  - The cleaned unemployment\_df contains 816 rows and 3 columns.

The final\_df is created by joining all 3 datasets by year and month. \*
The final\_df contains822 rows and 11 columns.
